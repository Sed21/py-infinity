
[tool.poetry]
name = "infinity_emb"
version = "0.1.0-cpu"
description = "High-performance CPU text embedding server"
authors = ["michaelfeil <noreply@michaelfeil.eu>"]
license = "MIT"
readme = "README.md"
packages = [{ include = "infinity_emb" }]
homepage = "https://github.com/Sed21/py-infinity"
repository = "https://github.com/Sed21/py-infinity"
keywords = [
    "vector",
    "embedding",
    "neural",
    "search",
    "sentence-transformers",
    "cpu",
]

[tool.poetry.dependencies]
python = ">=3.9,<3.14"
# basics, pin numpy <2 for onnx
numpy = ">=1.20.0,<2"
huggingface_hub = { version = ">=0.32.0" }
# logging
rich = { version = "^13", optional = true }
# webserver-only
fastapi = { version = ">=0.103.2", optional = true }
orjson = { version = ">=3.9.8,!=3.10.0", optional = true }
prometheus-fastapi-instrumentator = { version = ">=6.1.0", optional = true }
uvicorn = { version = "^0.32.0", optional = true, extras = ["standard"] }
typer = { version = "^0.12.5", optional = true }
pydantic = { version = ">=2.4.0,<3", optional = true }
# backend - CPU only torch from pytorch_cpu source
torch = { version = ">=2.2.1", source = "pytorch_cpu", optional = true }
sentence-transformers = { version = "^3.0.1", optional = true }
transformers = { version = ">=4.47.0,<=5.0", optional = true, extras = [
    "sentencepiece",
] }
ctranslate2 = { version = ">=4.0.0", optional = true }
optimum = { version = ">=1.24.0", optional = true, extras = ["onnxruntime"] }
# cache
diskcache = { version = "*", optional = true }

[tool.poetry.scripts]
infinity_emb = "infinity_emb.cli:cli"

[tool.poetry.group.test.dependencies]
pytest = "^8.0.0"
pytest-mock = "*"
httpx = "*"
asgi_lifespan = "*"
anyio = "*"
trio = "*"
coverage = { extras = ["toml"], version = "^7.3.2" }
mypy = "^1.12.0"
requests = "2.32.3"
types-requests = "2.28.1"
openai = "*"

[tool.poetry.group.lint.dependencies]
ruff = "^0.7.0"
types-toml = "^0.10.8.1"
black = "^24.10.0"

[tool.poetry.extras]
# CPU inference backends
ct2 = ["ctranslate2", "sentence-transformers", "torch", "transformers"]
optimum = ["optimum"]
torch = ["sentence-transformers", "torch"]
# utilities
logging = ["rich"]
cache = ["diskcache"]
# server
server = [
    "fastapi",
    "orjson",
    "prometheus-fastapi-instrumentator",
    "pydantic",
    "rich",
    "typer",
    "uvicorn",
]
# all CPU extras
all = [
    "ctranslate2",
    "diskcache",
    "fastapi",
    "optimum",
    "orjson",
    "prometheus-fastapi-instrumentator",
    "pydantic",
    "rich",
    "sentence-transformers",
    "torch",
    "typer",
    "uvicorn",
]

[[tool.poetry.source]]
name = "pypi"
priority = "primary"

[[tool.poetry.source]]
# CPU-only PyTorch wheels
name = "pytorch_cpu"
url = "https://download.pytorch.org/whl/cpu"
priority = "supplemental"

[tool.pytest.ini_options]
markers = [
    "performance: tests that measure performance (deselect with '-m \"not performance\"')",
]

[tool.ruff]
line-length = 100

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
